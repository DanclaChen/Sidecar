{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: 3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('/sidecar_after')\n",
    "\n",
    "gpu_list = [3]\n",
    "cuda_device = ','.join([str(i) for i in gpu_list])\n",
    "\n",
    "print(f'Using GPU: {cuda_device}')\n",
    "\n",
    "# cuda_device = '1,3'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = cuda_device\n",
    "\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import traceback\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import random\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from scipy import integrate\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "torch.cuda.is_available()\n",
    "\n",
    "\n",
    "from sidecar import parallel_train\n",
    "from parameters import params\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "torch.set_default_device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.multiprocessing as mp\n",
    "\n",
    "num_processes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "param_vector = [16, 32, 64, 128, 256]\n",
    "\n",
    "\n",
    "\n",
    "result_matrix = np.zeros((len(param_vector), 10, 14))\n",
    "\n",
    "\n",
    "i = 0\n",
    "\n",
    "for width in param_vector:\n",
    "    \n",
    "    shared_params = params()\n",
    "\n",
    "    shared_params.width = width\n",
    "    shared_params.learning_rate = 0.0001\n",
    "    shared_params.width_R = 8\n",
    "    shared_params.num_hidden_R = 1\n",
    "    shared_params.num_hidden = 2\n",
    "    shared_params.h_train = 2/256\n",
    "    shared_params.coe_without_R = 0.0\n",
    "    shared_params.coe_structure = 10.0\n",
    "    shared_params.batch_size = 2046\n",
    "    shared_params.tol = 100.0\n",
    "    shared_params.epoches_read = 20000\n",
    "    shared_params.epoches = 10000\n",
    "    # shared_params.gamma = 0.9999\n",
    "    # shared_params.Adam_proportion = 0.95\n",
    "\n",
    "    if __name__ == '__main__':\n",
    "        mp.set_start_method('spawn', force=True)\n",
    "\n",
    "        manager = mp.Manager()\n",
    "        results_queue = manager.Queue()\n",
    "\n",
    "        num_tasks = num_processes\n",
    "        num_gpus = len(gpu_list)\n",
    "\n",
    "        processes = []\n",
    "\n",
    "        for task_id in num_tasks:\n",
    "            \n",
    "            gpu_id = task_id % num_gpus\n",
    "\n",
    "            print(f\"Task {task_id} on GPU {gpu_list[gpu_id]}\")\n",
    "                \n",
    "            p = mp.Process(target=parallel_train, args=(task_id, shared_params, results_queue, gpu_id))\n",
    "            p.start()\n",
    "            processes.append(p)\n",
    "\n",
    "        for p in processes:\n",
    "            p.join()\n",
    "        \n",
    "\n",
    "        while not results_queue.empty():\n",
    "            (idx, loss_vector) = results_queue.get()\n",
    "            result_matrix[i, idx, :] = loss_vector\n",
    "\n",
    "    i += 1\n",
    "\n",
    "print(result_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
